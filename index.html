<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Welcome to the Computational Sonic Arts Lab | C4DM | QMUL |</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
<header id="title-block-header">
<h1 class="title">Welcome to the Computational Sonic Arts Lab | C4DM |
QMUL |</h1>
</header>
<p><img src="img/csal-logo.png" /></p>
<h1 id="computational-sonic-arts-laboratory">Computational Sonic Arts
Laboratory</h1>
<blockquote>
<p>The lab aims to become a research hub in developing sustainable,
inclusive, and forward-thinking technologies that transform how we
create, experience, and understand music.</p>
</blockquote>
<p>The Computational Sonic Arts Laboratory is a research team based in
the <a href="https://www.c4dm.eecs.qmul.ac.uk/">Centre for Digital
Music</a> (C4DM) at Queen Mary University of London dedicated to
advancing the intersection of sonic arts and cutting-edge technology.
The lab is led by <a href="https://www.c4dm.eecs.qmul.ac.uk/">Dr Anna
Xambó Sedó</a> and has been founded in 2025 as part of QMUL’s Centre for
Digital Music.</p>
<p>Rooted in principles of <strong>culture</strong>,
<strong>creativity</strong>, and <strong>community</strong>, the lab
explores <strong>sonic creativities</strong> and <strong>creative
computing</strong> through innovative research in <strong>creative
AI</strong>, <strong>music AI</strong>, and <strong>intelligent music
systems</strong>. The vision of the lab is to bridge
<strong>HCI</strong>, <strong>sound and music computing</strong>, and
<strong>new interfaces for musical expression</strong>, by emphasising
<strong>live coding</strong>, <strong>network music</strong>, and
<strong>generative sound-based music</strong>. The lab aims to become a
research hub in developing sustainable, inclusive, and forward-thinking
technologies that transform how we create, experience, and understand
music.</p>
<p><strong>Research activities include:</strong></p>
<ul>
<li>The design, deployment and evaluation of intelligent sound-based
music systems that keep the human in the loop and give ownership to
communities of practice and perspectives generally underrepresented in
music AI.</li>
<li>The creation of sound-based music performances and sonic arts
experiences that foster democratic principles in music making and raise
awareness of real-world problems.</li>
<li>The design and development of sustainable and DIY systems based on
interdisciplinary methods involving art, science and engineering and in
alignment with open source, open hardware, citizen science and the <a
href="https://makezine.com/article/maker-news/the-makers-bill-of-rights/">Maker’s
Bill of Rights</a>.</li>
</ul>
<p>The lab hosts the AHRC-funded project <a
href="https://sensingtheforest.github.io/">Sensing the Forest - Let the
Forest Speak using the Internet of Things, Acoustic Ecology and Creative
AI</a>, which pursues raising awareness and understanding of forest
environmental data and how they relate to climate change.</p>
<p>Please, get in touch if you are interested in PhD opportunities. The
Centre for Digital Music of Queen Mary University of London <a
href="https://www.c4dm.eecs.qmul.ac.uk/get-involved/">welcomes PhD
applications for 2025</a>.</p>
<h2 id="news">News</h2>
<h3 id="may-2025">May 2025</h3>
<h4 id="dr-anna-xambó---keynote-paper-and-performance-at-iclc2025">Dr
Anna Xambó - keynote, paper and performance at ICLC2025</h4>
<p><img src="img/iclc-logo-2025-black.png" /> <em>ICLC 2025
logo</em></p>
<p>CSAL’s Anna Xambó will be giving a keynote on Wednesday 28 May
16:30-17:30 on “Liveness as an open work: an ongoing live-coding
algorithmic journey” at the International Conference on Live Coding
(ICLC).</p>
<p>On Thursday 29 May she will also deliver the paper co-authored paper
<a
href="https://iclc.toplap.org/2025/catalogue/paper/building-a-dataset-of-personal-live-coding-style-using-a-journal.html">“Building
a Dataset of Personal Live Coding Style Using MIRLCaProxy - A Journal of
Creative Sonic Exploration under Constraints and Biases”</a> and will
perform in the evening the live-coding session <a
href="https://iclc.toplap.org/2025/catalogue/performance/sensing-the-alice-holt-forest.html">“Sensing
the Alice Holt Forest”</a>.</p>
<p>For more info visit: <a
href="https://iclc.toplap.org/2025/">https://iclc.toplap.org/2025/</a></p>
<h4 id="bsc-student-stanley-parker-wins-a-hackathon">BSc student Stanley
Parker wins a hackathon</h4>
<p><img src="img/bluecrabs.jpg" /> <em>BlueCrabs team at the Open Sea
Lab 4.0 Hackathon</em></p>
<p><a
href="https://www.qmul.ac.uk/eecs/news-and-events/news/items/crab-alert-hackathon-team-builds-award-winning-early-warning-system-for-invasive-species.html">Crab
Alert: Hackathon team builds award-winning early warning system for
invasive species.</a> Stanley Parker, a third-year BSc Creative
Computing student at the School of Electronic Engineering and Computer
Science, recently took part in Open Sea Lab 4.0, a prestigious
international hackathon focused on ocean innovation.</p>
<h3 id="feb-2025">Feb 2025</h3>
<h4 id="phd-position-available-at-the-lab">PhD position available at the
lab</h4>
<p><img
src="img/craiyon_162415_Nature_inspired_computing_for_sound_based_DIY_approaches_to_creative_AI_opt.png" />
<em>Image generated using <a href="https://www.craiyon.com">Craiyon
AI</a></em></p>
<p>We are happy to announce an exciting PhD position to work on
<strong>“Nature-inspired computing for sound-based DIY approaches to
creative AI”</strong> at the Centre for Digital Music, School of
Electronic Engineering and Computer Science, Queen Mary University of
London.</p>
<ul>
<li>Application deadline: <strong>28th February 2025</strong></li>
<li>Requirements: <strong>UK home student</strong></li>
<li>How to apply: <strong><a
href="https://www.qmul.ac.uk/eecs/phd/how-to-apply/">https://www.qmul.ac.uk/eecs/phd/how-to-apply/</a></strong></li>
<li>You can find more info here: <strong><a
href="https://www.findaphd.com/phds/project/nature-inspired-computing-for-sound-based-diy-approaches-to-creative-ai/?p182149">https://www.findaphd.com/phds/project/nature-inspired-computing-for-sound-based-diy-approaches-to-creative-ai/?p182149</a></strong></li>
</ul>
<h2 id="team">Team</h2>
<ul>
<li><a href="https://annaxambo.me/">Dr Anna Xambó</a> (Senior Lecturer
in Sound and Music Computing, Queen Mary University of London)</li>
<li><a href="http://www.luigimarino.net/">Dr Luigi Marino</a> (Research
Fellow in Sound and Music Computing, Queen Mary University of
London)</li>
<li><a href="https://jasperzheng.cc/">Shuoyang Zheng</a> (PhD student,
AIM/C4DM, Queen Mary University of London)</li>
<li><a href="https://uk.linkedin.com/in/qiaoxi-z-2a2b39137">Qiaoxi
Zhang</a> (PhD student, AIM/C4DM, Queen Mary University of London)</li>
<li>Xinyue Xu (MSc Sound and Music Computing, Queen Mary University of
London)</li>
<li><a
href="https://www.linkedin.com/in/andres-sanchez-59a8331a6/">Andrés
Sánchez Castrillón</a> (MSc Artificial Intelligence, Queen Mary
University of London)</li>
<li><a href="https://tugoflaherty.com/">Tug O’Flaherty</a> (MSc Sound
and Music Computing, Queen Mary University of London)</li>
<li>James Shortland (MSc Data Science and Artificial Intelligence, Queen
Mary University of London)</li>
<li><a
href="https://www.linkedin.com/in/aleksander-skutnik-1a05a625a/">Aleksander
Skutnik</a> (BSc Computer Science, Queen Mary University of London)</li>
<li><a
href="https://www.linkedin.com/in/stanley-parker-43113425a">Stanley
Parker</a> (BSc Creative Computing, Queen Mary University of
London)</li>
<li>Ning Liu (BSc(Eng)FT Electronic Engineering, Queen Mary University
of London)</li>
<li>Amrina Kaur Virk (BSc Creative Computing, Queen Mary University of
London)</li>
</ul>
<h2 id="publications">Publications</h2>
<ul>
<li>Xambó, A., Roma, G. (2025 forthcoming) Building a Dataset of
Personal Live Coding Style Using MIRLCaProxy - A Journal of Creative
Sonic Exploration under Constraints and Biases. <em>Proceedings of the
International Conference of Live Coding</em>.</li>
<li>O’Flaherty, T. F., Marino, L., Saitis, C., Xambó, A. (2025
forthcoming) Sonicolour: Exploring Colour Control of Sound Synthesis
with Interactive Machine Learning. <em>Proceedings of the New Interfaces
for Musical Expression</em>.</li>
<li>Xambó, A. (2025) <a href="https://zenodo.org/records/15283062">Live
Coding a Chorale of Sounds Using MIRLCa: State of Affairs and
Implications</a>. <em>SuperCollider Symposium 2025</em>, Johns Hopkins
University Bloomberg Center, Washington D.C., USA. <a
href="https://doi.org/10.5281/zenodo.15283062">https://doi.org/10.5281/zenodo.15283062</a></li>
<li>Xambó, A., Roma, G. (2024) <a
href="https://www.tandfonline.com/doi/full/10.1080/09298215.2024.2442355">Human–machine
agencies in live coding for music performance</a>. <em>Journal of New
Music Research</em>, 53(1–2), 33–46. <a
href="https://doi.org/10.1080/09298215.2024.2442355">https://doi.org/10.1080/09298215.2024.2442355</a>.</li>
<li>Marino, L., Xambó, A. (2024) <a
href="https://static1.squarespace.com/static/6227c31a43daf21135453605/t/673e659f730d2433d5916462/1732142495610/21+Luigi+Marino+and+Anna+Xambo%CC%81.pdf">Developing
DIY solar-powered, off-grid audio streamers for forest soundscapes:
progress and challenges</a>. <em>Proceedings of CHIME Annual
Conference</em>, The Open University, 1-2 December 2024.</li>
</ul>
</body>
</html>
